{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment\n",
    "## Готовим LDA по рецептам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже знаете, в тематическом моделировании делается предположение о том, что для определения тематики порядок слов в документе не важен; об этом гласит гипотеза <<мешка слов>>. Сегодня мы будем работать с несколько нестандартной для тематического моделирования коллекцией, которую можно назвать <<мешком ингредиентов>>, потому что на состоит из рецептов блюд разных кухонь. Тематические модели ищут слова, которые часто вместе встречаются в документах, и составляют из них темы. Мы попробуем применить эту идею к рецептам и найти кулинарные <<темы>>. Эта коллекция хороша тем, что не требует предобработки. Кроме того, эта задача достаточно наглядно иллюстрирует принцип работы тематических моделей.\n",
    "\n",
    "Для выполнения заданий, помимо часто используемых в курсе библиотек, потребуются модули json и gensim. Первый входит в дистрибутив Anaconda, второй можно поставить командой \n",
    "\n",
    "pip install gensim\n",
    "\n",
    "или\n",
    "\n",
    "conda install gensim\n",
    "\n",
    "Построение модели занимает некоторое время. На ноутбуке с процессором Intel Core i7 и тактовой частотой 2400 МГц на построение одной модели уходит менее 10 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллекция дана в json-формате: для каждого рецепта известны его id, кухня (\"cuisine\") и список ингредиентов, в него входящих. Загрузить данные можно с помощью модуля json (он входит в дистрибутив Anaconda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"recipes.json\") as f:\n",
    "    recipes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ingredients': ['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles'], 'id': 10259, 'cuisine': 'greek'}\n"
     ]
    }
   ],
   "source": [
    "print(recipes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составление корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша коллекция небольшая и влезает в оперативную память. Gensim может работать с такими данными и не требует их сохранения на диск в специальном формате. Для этого коллекция должна быть представлена в виде списка списков, каждый внутренний список соответствует отдельному документу и состоит из его слов. Пример коллекции из двух документов: \n",
    "\n",
    "[[\"hello\", \"world\"], [\"programming\", \"in\", \"python\"]]\n",
    "\n",
    "Преобразуем наши данные в такой формат, а затем создадим объекты corpus и dictionary, с которыми будет работать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [recipe[\"ingredients\"] for recipe in recipes]\n",
    "dictionary = corpora.Dictionary(texts)   # составляем словарь\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта dictionary есть две полезных переменных: dictionary.id2token и dictionary.token2id; эти словари позволяют находить соответствие между ингредиентами и их индексами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Вам может понадобиться [документация](https://radimrehurek.com/gensim/models/ldamodel.html) LDA в gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучите модель LDA с 40 темами, установив количество проходов по коллекции 5 и оставив остальные параметры по умолчанию. Затем вызовите метод модели show_topics, указав количество тем 40 и количество токенов 10, и сохраните результат (топы ингредиентов в темах) в отдельную переменную. Если при вызове метода show_topics указать параметр formatted=True, то топы ингредиентов будет удобно выводить на печать, если formatted=False, будет удобно работать со списком программно. Выведите топы на печать, рассмотрите темы, а затем ответьте на вопрос:\n",
    "\n",
    "Сколько раз ингредиенты \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\" встретились среди топов-10 всех 40 тем? При ответе __не нужно__ учитывать составные ингредиенты, например, \"hot water\".\n",
    "\n",
    "Передайте 6 чисел в функцию save_answers1 и загрузите сгенерированный файл в форму.\n",
    "\n",
    "У gensim нет возможности фиксировать случайное приближение через параметры метода, но библиотека использует numpy для инициализации матриц. Поэтому, по утверждению автора библиотеки, фиксировать случайное приближение нужно командой, которая написана в следующей ячейке. __Перед строкой кода с построением модели обязательно вставляйте указанную строку фиксации random.seed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers1(c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs):\n",
    "    with open(\"cooking_LDA_pa_task1.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(76543)\n",
    "model = models.ldamodel.LdaModel(corpus=corpus, num_topics=40, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('45', 0.076982971656143387),\n",
       "   ('305', 0.076006488298713815),\n",
       "   ('11', 0.053001971841181973),\n",
       "   ('55', 0.051177733676344442),\n",
       "   ('22', 0.043096888130629889),\n",
       "   ('84', 0.0397969302135531),\n",
       "   ('128', 0.034968982031880778),\n",
       "   ('554', 0.029240238805320028),\n",
       "   ('12', 0.028805109095701057),\n",
       "   ('36', 0.028039209143666276)]),\n",
       " (1,\n",
       "  [('120', 0.055920005797528288),\n",
       "   ('181', 0.055543284409957094),\n",
       "   ('486', 0.054301629125219096),\n",
       "   ('1174', 0.04184350765470881),\n",
       "   ('1050', 0.041212706987356615),\n",
       "   ('1211', 0.040744861921155236),\n",
       "   ('1085', 0.036649252631752151),\n",
       "   ('29', 0.034924306112800535),\n",
       "   ('756', 0.03243804759156927),\n",
       "   ('585', 0.029866680542748842)]),\n",
       " (2,\n",
       "  [('55', 0.071390557322931023),\n",
       "   ('11', 0.051098264513947528),\n",
       "   ('77', 0.045410810624427082),\n",
       "   ('103', 0.040933838054010491),\n",
       "   ('490', 0.038914140829257329),\n",
       "   ('3', 0.033802552794070462),\n",
       "   ('12', 0.031451282325837181),\n",
       "   ('19', 0.031030695304113808),\n",
       "   ('391', 0.028769675982427502),\n",
       "   ('553', 0.026100555091856749)]),\n",
       " (3,\n",
       "  [('314', 0.22326324928948546),\n",
       "   ('555', 0.067222211032255577),\n",
       "   ('319', 0.056678517100441521),\n",
       "   ('686', 0.044346471530897345),\n",
       "   ('76', 0.037193695365119107),\n",
       "   ('1036', 0.030018304940044215),\n",
       "   ('434', 0.028136177806839659),\n",
       "   ('590', 0.028048615326658692),\n",
       "   ('1339', 0.023917273329442646),\n",
       "   ('397', 0.023840579913511663)]),\n",
       " (4,\n",
       "  [('209', 0.098870994012440774),\n",
       "   ('213', 0.070445923683949488),\n",
       "   ('11', 0.0479452979220217),\n",
       "   ('22', 0.036138635130597785),\n",
       "   ('874', 0.03563776292500842),\n",
       "   ('737', 0.034926491909790768),\n",
       "   ('625', 0.033611858542043661),\n",
       "   ('439', 0.027147404083033778),\n",
       "   ('15', 0.025932507951071979),\n",
       "   ('95', 0.025899691825369789)]),\n",
       " (5,\n",
       "  [('11', 0.088583023714964348),\n",
       "   ('61', 0.070117809318677712),\n",
       "   ('3', 0.067854784607595336),\n",
       "   ('68', 0.062688055659829017),\n",
       "   ('113', 0.055900991870113909),\n",
       "   ('110', 0.046148992968442284),\n",
       "   ('1', 0.045172950542614117),\n",
       "   ('19', 0.044438848451437724),\n",
       "   ('58', 0.040345235487766917),\n",
       "   ('840', 0.038987105584716103)]),\n",
       " (6,\n",
       "  [('28', 0.10566869697101158),\n",
       "   ('187', 0.10176177897152065),\n",
       "   ('40', 0.053290663291528026),\n",
       "   ('949', 0.046082939073278061),\n",
       "   ('525', 0.042283193779732248),\n",
       "   ('62', 0.037327433392223705),\n",
       "   ('42', 0.03501688443312749),\n",
       "   ('12', 0.030710943499903547),\n",
       "   ('79', 0.027786680741259933),\n",
       "   ('419', 0.025659124800512287)]),\n",
       " (7,\n",
       "  [('271', 0.10546269748700265),\n",
       "   ('577', 0.064321945687514884),\n",
       "   ('204', 0.063498306141481067),\n",
       "   ('245', 0.056114560263402488),\n",
       "   ('75', 0.038873981099487101),\n",
       "   ('43', 0.038207368797863524),\n",
       "   ('519', 0.036295381851000945),\n",
       "   ('144', 0.02572501446844366),\n",
       "   ('73', 0.024463802911079243),\n",
       "   ('697', 0.023671928528529871)]),\n",
       " (8,\n",
       "  [('18', 0.10675549719530593),\n",
       "   ('10', 0.10121596079331295),\n",
       "   ('11', 0.08428523489323575),\n",
       "   ('22', 0.081668795809388461),\n",
       "   ('63', 0.079856234249116378),\n",
       "   ('53', 0.056447499228387078),\n",
       "   ('29', 0.028185752088693637),\n",
       "   ('597', 0.024589614709152222),\n",
       "   ('1073', 0.02237212127295983),\n",
       "   ('4', 0.019094768431285714)]),\n",
       " (9,\n",
       "  [('1336', 0.04282106805353568),\n",
       "   ('313', 0.04090044940781036),\n",
       "   ('533', 0.039902560620211941),\n",
       "   ('1743', 0.039760451677312979),\n",
       "   ('879', 0.039664019179356136),\n",
       "   ('55', 0.038999423137796682),\n",
       "   ('119', 0.037219821446912556),\n",
       "   ('36', 0.032181397505044451),\n",
       "   ('11', 0.031706145207522025),\n",
       "   ('400', 0.031254991619129549)]),\n",
       " (10,\n",
       "  [('707', 0.052555237299654396),\n",
       "   ('938', 0.046504227808947418),\n",
       "   ('176', 0.040878601378825527),\n",
       "   ('1528', 0.036679762649266458),\n",
       "   ('300', 0.031834557057071049),\n",
       "   ('598', 0.02956196766588336),\n",
       "   ('668', 0.029420046747040095),\n",
       "   ('682', 0.029266921377301865),\n",
       "   ('960', 0.027092537094678314),\n",
       "   ('630', 0.026338116576475133)]),\n",
       " (11,\n",
       "  [('464', 0.059828860659191699),\n",
       "   ('79', 0.054382242082853187),\n",
       "   ('1', 0.050004230601201342),\n",
       "   ('60', 0.041290090394866162),\n",
       "   ('467', 0.038747976774498046),\n",
       "   ('55', 0.038283513979577403),\n",
       "   ('23', 0.037055089634967397),\n",
       "   ('873', 0.029767118586281366),\n",
       "   ('350', 0.027655624662172848),\n",
       "   ('103', 0.025797782636961718)]),\n",
       " (12,\n",
       "  [('730', 0.13657444175777583),\n",
       "   ('274', 0.060695893443767704),\n",
       "   ('798', 0.058884882798762944),\n",
       "   ('142', 0.05721947230873084),\n",
       "   ('190', 0.049746647546630302),\n",
       "   ('227', 0.042082259133490854),\n",
       "   ('302', 0.03745911579010261),\n",
       "   ('36', 0.029344795316199667),\n",
       "   ('1044', 0.029299424695894614),\n",
       "   ('87', 0.028577527068561637)]),\n",
       " (13,\n",
       "  [('404', 0.090598521984040614),\n",
       "   ('448', 0.076940387475529393),\n",
       "   ('99', 0.066373432162825249),\n",
       "   ('789', 0.058612663616318728),\n",
       "   ('827', 0.0495218290030544),\n",
       "   ('309', 0.043507591647283905),\n",
       "   ('124', 0.040346897660399117),\n",
       "   ('308', 0.035403433480332328),\n",
       "   ('749', 0.030693218376913439),\n",
       "   ('276', 0.02921430267527652)]),\n",
       " (14,\n",
       "  [('78', 0.06559700873792973),\n",
       "   ('307', 0.061119909487201342),\n",
       "   ('55', 0.059889910171449859),\n",
       "   ('188', 0.050709347469700176),\n",
       "   ('11', 0.046861689055581794),\n",
       "   ('230', 0.044764734542748284),\n",
       "   ('103', 0.044496884027386607),\n",
       "   ('83', 0.032800665398067232),\n",
       "   ('118', 0.029767601079591602),\n",
       "   ('500', 0.021459058746919626)]),\n",
       " (15,\n",
       "  [('191', 0.16065533619915312),\n",
       "   ('311', 0.14564462203102163),\n",
       "   ('441', 0.069344569589893046),\n",
       "   ('459', 0.05623907970405756),\n",
       "   ('50', 0.041562604892565573),\n",
       "   ('79', 0.035088551343642228),\n",
       "   ('803', 0.031007999318265429),\n",
       "   ('132', 0.028717085479460218),\n",
       "   ('702', 0.027725172614061253),\n",
       "   ('460', 0.027129812013070388)]),\n",
       " (16,\n",
       "  [('228', 0.080242076816783262),\n",
       "   ('146', 0.069676703812525789),\n",
       "   ('36', 0.061177986799951907),\n",
       "   ('200', 0.051937879073970204),\n",
       "   ('37', 0.04725658823531298),\n",
       "   ('55', 0.040377558241251943),\n",
       "   ('43', 0.03525414364191936),\n",
       "   ('11', 0.034669367239461402),\n",
       "   ('1', 0.028615711863733496),\n",
       "   ('227', 0.023293957935036282)]),\n",
       " (17,\n",
       "  [('432', 0.0929023660827175),\n",
       "   ('669', 0.076414698662258765),\n",
       "   ('646', 0.073396812456205052),\n",
       "   ('433', 0.07243562666816962),\n",
       "   ('621', 0.051985157913376316),\n",
       "   ('251', 0.047468264648236232),\n",
       "   ('431', 0.039219371377701581),\n",
       "   ('241', 0.03856133374007454),\n",
       "   ('29', 0.029347387288341908),\n",
       "   ('1286', 0.023517887648534748)]),\n",
       " (18,\n",
       "  [('148', 0.083439137695740462),\n",
       "   ('164', 0.071347710392759334),\n",
       "   ('203', 0.066966635726777413),\n",
       "   ('270', 0.057259409733351668),\n",
       "   ('157', 0.040253376322449533),\n",
       "   ('1343', 0.032686879987386251),\n",
       "   ('1395', 0.02916520530865593),\n",
       "   ('1089', 0.028809943166330922),\n",
       "   ('940', 0.02638393617456784),\n",
       "   ('521', 0.026147176041695853)]),\n",
       " (19,\n",
       "  [('321', 0.10304182537513287),\n",
       "   ('1223', 0.048182475100058228),\n",
       "   ('703', 0.047859758955429862),\n",
       "   ('1348', 0.045033791404173629),\n",
       "   ('273', 0.042536628779240346),\n",
       "   ('339', 0.040284197923680869),\n",
       "   ('360', 0.032081767342536219),\n",
       "   ('359', 0.031956928713725928),\n",
       "   ('1570', 0.029274559954221402),\n",
       "   ('480', 0.025397674606502732)]),\n",
       " (20,\n",
       "  [('36', 0.071742096970665928),\n",
       "   ('215', 0.069217904925082632),\n",
       "   ('327', 0.069020112029264363),\n",
       "   ('175', 0.051622647568351714),\n",
       "   ('928', 0.046673828864191233),\n",
       "   ('565', 0.043611572035047216),\n",
       "   ('9', 0.043360206224285464),\n",
       "   ('11', 0.043277769767526932),\n",
       "   ('911', 0.036898764891540779),\n",
       "   ('4', 0.033808858403417082)]),\n",
       " (21,\n",
       "  [('237', 0.078166987736098634),\n",
       "   ('208', 0.051592285033923463),\n",
       "   ('212', 0.04897062582714376),\n",
       "   ('227', 0.040876647538322396),\n",
       "   ('916', 0.036769904201479645),\n",
       "   ('234', 0.031983396405361332),\n",
       "   ('211', 0.029910310432673337),\n",
       "   ('12', 0.029722878702230827),\n",
       "   ('235', 0.029685571437990339),\n",
       "   ('192', 0.02925671593264087)]),\n",
       " (22,\n",
       "  [('252', 0.11455915133864907),\n",
       "   ('596', 0.060169017207233222),\n",
       "   ('1242', 0.048314033105298387),\n",
       "   ('416', 0.04799143736381651),\n",
       "   ('74', 0.040185771056679018),\n",
       "   ('569', 0.038790097389873962),\n",
       "   ('522', 0.032536311730376244),\n",
       "   ('1031', 0.031981446063523628),\n",
       "   ('334', 0.023982752066051431),\n",
       "   ('1777', 0.022428782667886806)]),\n",
       " (23,\n",
       "  [('20', 0.101088119161485),\n",
       "   ('91', 0.051754603766480181),\n",
       "   ('53', 0.043978052526878468),\n",
       "   ('1', 0.041701897866763767),\n",
       "   ('96', 0.039976181559999123),\n",
       "   ('227', 0.034844174444637492),\n",
       "   ('29', 0.032262201706037677),\n",
       "   ('90', 0.032236914852918172),\n",
       "   ('361', 0.031740813648502564),\n",
       "   ('11', 0.029524377647968812)]),\n",
       " (24,\n",
       "  [('141', 0.089176599775448853),\n",
       "   ('70', 0.069396982372971719),\n",
       "   ('103', 0.046084663602443073),\n",
       "   ('562', 0.034306829029946549),\n",
       "   ('11', 0.03358084230445478),\n",
       "   ('79', 0.025483046047562279),\n",
       "   ('53', 0.025028760526387472),\n",
       "   ('860', 0.024632018928548632),\n",
       "   ('37', 0.02411309698540974),\n",
       "   ('820', 0.023417706201799324)]),\n",
       " (25,\n",
       "  [('11', 0.076669709408418871),\n",
       "   ('36', 0.056014092834438339),\n",
       "   ('346', 0.041055402881171266),\n",
       "   ('44', 0.038630689005429208),\n",
       "   ('46', 0.03789577477546141),\n",
       "   ('275', 0.034996503255996667),\n",
       "   ('37', 0.033173048968449928),\n",
       "   ('126', 0.031731732808651096),\n",
       "   ('1', 0.030850552030296491),\n",
       "   ('349', 0.030259034833267941)]),\n",
       " (26,\n",
       "  [('102', 0.17409676092474691),\n",
       "   ('77', 0.049264968369976819),\n",
       "   ('375', 0.04013149630201588),\n",
       "   ('103', 0.039968891472133769),\n",
       "   ('11', 0.036998990016276052),\n",
       "   ('172', 0.036081206305374793),\n",
       "   ('55', 0.035900505837790725),\n",
       "   ('551', 0.034016954206362873),\n",
       "   ('510', 0.032498942868147501),\n",
       "   ('12', 0.030213768338061379)]),\n",
       " (27,\n",
       "  [('77', 0.11739850745413176),\n",
       "   ('255', 0.075258314169435153),\n",
       "   ('11', 0.056900321302291376),\n",
       "   ('396', 0.048309413520425809),\n",
       "   ('57', 0.040247632003897096),\n",
       "   ('699', 0.032809692286778838),\n",
       "   ('103', 0.032777376941787686),\n",
       "   ('861', 0.031980996858813074),\n",
       "   ('79', 0.030415367628003651),\n",
       "   ('55', 0.029834037858320568)]),\n",
       " (28,\n",
       "  [('36', 0.088613271719701001),\n",
       "   ('11', 0.068690712803748555),\n",
       "   ('198', 0.062952728351756332),\n",
       "   ('1', 0.04517494115776631),\n",
       "   ('29', 0.039199463800154981),\n",
       "   ('210', 0.039030860209479622),\n",
       "   ('34', 0.034449251083190732),\n",
       "   ('4', 0.034229280648126734),\n",
       "   ('55', 0.032100950439312249),\n",
       "   ('248', 0.031424142179892103)]),\n",
       " (29,\n",
       "  [('1077', 0.078298214497411214),\n",
       "   ('746', 0.048629986707287208),\n",
       "   ('53', 0.042681140466245909),\n",
       "   ('711', 0.028665162602805605),\n",
       "   ('888', 0.026956931393927838),\n",
       "   ('828', 0.026759560801062111),\n",
       "   ('317', 0.026487750513915016),\n",
       "   ('853', 0.024325708908846101),\n",
       "   ('1366', 0.022738687910267348),\n",
       "   ('2029', 0.022368501425440279)]),\n",
       " (30,\n",
       "  [('53', 0.12638822218502646),\n",
       "   ('304', 0.069021392302470105),\n",
       "   ('48', 0.053170377978363999),\n",
       "   ('532', 0.051550292570576368),\n",
       "   ('364', 0.047000580013045197),\n",
       "   ('29', 0.044275456315179554),\n",
       "   ('205', 0.037110376300090737),\n",
       "   ('201', 0.034643831107070769),\n",
       "   ('407', 0.031656783371423379),\n",
       "   ('11', 0.029683851122788357)]),\n",
       " (31,\n",
       "  [('280', 0.11258463771865669),\n",
       "   ('11', 0.055457853411840952),\n",
       "   ('207', 0.054689003341726293),\n",
       "   ('103', 0.051890318857915264),\n",
       "   ('306', 0.045261439947574443),\n",
       "   ('504', 0.039711421958691831),\n",
       "   ('115', 0.039589526455754684),\n",
       "   ('29', 0.0374715596170411),\n",
       "   ('773', 0.037074890212978197),\n",
       "   ('118', 0.036083878605264096)]),\n",
       " (32,\n",
       "  [('225', 0.08934461324017659),\n",
       "   ('357', 0.05288041515396523),\n",
       "   ('1', 0.037650140287642013),\n",
       "   ('68', 0.031955631574158136),\n",
       "   ('338', 0.03016346495479966),\n",
       "   ('53', 0.030031704438525507),\n",
       "   ('29', 0.026557999686869515),\n",
       "   ('198', 0.026002985657255454),\n",
       "   ('995', 0.025020499564607536),\n",
       "   ('129', 0.024452720986764438)]),\n",
       " (33,\n",
       "  [('578', 0.11126544660788255),\n",
       "   ('641', 0.072172846123474604),\n",
       "   ('721', 0.060702139327245289),\n",
       "   ('481', 0.059787879497508502),\n",
       "   ('505', 0.053609908442986319),\n",
       "   ('170', 0.053280238887833405),\n",
       "   ('86', 0.040248704604890453),\n",
       "   ('1311', 0.034757709771121192),\n",
       "   ('195', 0.030645915202653203),\n",
       "   ('402', 0.023858522072323748)]),\n",
       " (34,\n",
       "  [('25', 0.075556613503413972),\n",
       "   ('11', 0.057184399085087045),\n",
       "   ('188', 0.043306532879780334),\n",
       "   ('1', 0.043304181019252395),\n",
       "   ('216', 0.03867472846254108),\n",
       "   ('713', 0.035197848142459777),\n",
       "   ('4', 0.035160297438590588),\n",
       "   ('394', 0.034017649643354374),\n",
       "   ('262', 0.032602003212027081),\n",
       "   ('55', 0.032408594164050564)]),\n",
       " (35,\n",
       "  [('52', 0.11544682789526627),\n",
       "   ('51', 0.062992726148172057),\n",
       "   ('369', 0.054208131992209488),\n",
       "   ('389', 0.046966260578958384),\n",
       "   ('446', 0.039355665693539606),\n",
       "   ('495', 0.037754013848586163),\n",
       "   ('542', 0.037266105328494878),\n",
       "   ('830', 0.027784365214768288),\n",
       "   ('388', 0.026914442727205858),\n",
       "   ('513', 0.025661254751573711)]),\n",
       " (36,\n",
       "  [('54', 0.095391416975710061),\n",
       "   ('149', 0.076245450555699326),\n",
       "   ('220', 0.070363546799684651),\n",
       "   ('206', 0.053849480356866535),\n",
       "   ('155', 0.052844143740732583),\n",
       "   ('501', 0.039017328587065671),\n",
       "   ('14', 0.03674419843914449),\n",
       "   ('482', 0.031090245890500683),\n",
       "   ('151', 0.025683881399095582),\n",
       "   ('1572', 0.025324518867076529)]),\n",
       " (37,\n",
       "  [('121', 0.16302859875901154),\n",
       "   ('11', 0.10131042828495664),\n",
       "   ('201', 0.088134080374078827),\n",
       "   ('47', 0.059104729710040493),\n",
       "   ('22', 0.047902186310940217),\n",
       "   ('53', 0.046927976962497023),\n",
       "   ('311', 0.045378392620879685),\n",
       "   ('310', 0.038000285655980078),\n",
       "   ('290', 0.033286785666502415),\n",
       "   ('10', 0.029808352007935718)]),\n",
       " (38,\n",
       "  [('229', 0.097264850545365267),\n",
       "   ('477', 0.083179535815715314),\n",
       "   ('29', 0.072085128165738421),\n",
       "   ('11', 0.069049791318578788),\n",
       "   ('320', 0.052610885019654163),\n",
       "   ('199', 0.051076220376126101),\n",
       "   ('24', 0.040197954445412208),\n",
       "   ('1', 0.032843311183230119),\n",
       "   ('18', 0.032033487676905982),\n",
       "   ('36', 0.030800901629714952)]),\n",
       " (39,\n",
       "  [('214', 0.087760673976439801),\n",
       "   ('55', 0.0772546407504828),\n",
       "   ('679', 0.04732623705630374),\n",
       "   ('11', 0.0453605839734567),\n",
       "   ('22', 0.044729552561556252),\n",
       "   ('12', 0.035560891340588326),\n",
       "   ('121', 0.031748981954884126),\n",
       "   ('36', 0.030722832091069671),\n",
       "   ('476', 0.028903841977693599),\n",
       "   ('188', 0.027448364197368937)])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topics(num_topics=40, num_words=10, formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 7, 9, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "params1 = [\n",
    "    sum(\n",
    "        str(dictionary.token2id[token]) == _id\n",
    "        for topic, top in model.show_topics(num_topics=40, num_words=10, formatted=False)\n",
    "        for _id, _ in top\n",
    "    )\n",
    "    for token in [\"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\"]\n",
    "]\n",
    "print(params1)\n",
    "save_answers1(*params1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация словаря\n",
    "В топах тем гораздо чаще встречаются первые три рассмотренных ингредиента, чем последние три. При этом наличие в рецепте курицы, яиц и грибов яснее дает понять, что мы будем готовить, чем наличие соли, сахара и воды. Таким образом, даже в рецептах есть слова, часто встречающиеся в текстах и не несущие смысловой нагрузки, и поэтому их не желательно видеть в темах. Наиболее простой прием борьбы с такими фоновыми элементами - фильтрация словаря по частоте. Обычно словарь фильтруют с двух сторон: убирают очень редкие слова (в целях экономии памяти) и очень частые слова (в целях повышения интерпретируемости тем). Мы уберем только частые слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ У объекта dictionary2 есть переменная dfs - это словарь, ключами которого являются id токена, а элементами - число раз, сколько слово встретилось во всей коллекции. Сохраните в отдельный список ингредиенты, которые встретились в коллекции больше 4000 раз. Вызовите метод словаря filter_tokens, подав в качестве первого аргумента полученный список популярных ингредиентов. Вычислите две величины: dict_size_before и dict_size_after - размер словаря до и после фильтрации.\n",
    "\n",
    "Затем, используя новый словарь, создайте новый корпус документов, corpus2, по аналогии с тем, как это сделано в начале ноутбука. Вычислите две величины: corpus_size_before и corpus_size_after - суммарное количество ингредиентов в корпусе (иными словами, сумма длин всех документов коллекции) до и после фильтрации.\n",
    "\n",
    "Передайте величины dict_size_before, dict_size_after, corpus_size_before, corpus_size_after в функцию save_answers2 и загрузите сгенерированный файл в форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top: [(11, 18048), (36, 7972), (55, 7971), (29, 7457), (1, 7380), (53, 6434), (103, 6236), (22, 4847), (12, 4784), (121, 4632), (4, 4438), (14, 4385), (18, 3388), (20, 3296), (79, 3113), (227, 3078), (19, 3058), (201, 2948), (198, 2814), (311, 2782)]\n",
      "IDs: [1, 4, 11, 12, 14, 22, 29, 36, 53, 55, 103, 121]\n",
      "Dict size before: 6714\n",
      "Dict size after: 6702\n",
      "Corpus size before: 428249\n",
      "Corpus size after: 343665\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "dictionary2 = copy.deepcopy(dictionary)\n",
    "\n",
    "print(\"Top:\", sorted(dictionary2.dfs.items(), key=lambda item: item[1], reverse=True)[:20])\n",
    "ids2 = [_id for _id, freq in dictionary2.dfs.items() if freq > 4000]\n",
    "print(\"IDs:\", ids2)\n",
    "\n",
    "dict_size_before = len(dictionary)\n",
    "print(\"Dict size before:\", dict_size_before)\n",
    "dictionary2.filter_tokens(ids2)\n",
    "dict_size_after = len(dictionary2)\n",
    "print(\"Dict size after:\", dict_size_after)\n",
    "\n",
    "corpus_size_before = sum(1 for doc in corpus for _, count in doc)\n",
    "print(\"Corpus size before:\", corpus_size_before)\n",
    "corpus2 = [dictionary2.doc2bow(text) for text in texts]\n",
    "corpus_size_after = sum(1 for doc in corpus2 for _, count in doc)\n",
    "print(\"Corpus size after:\", corpus_size_after)\n",
    "\n",
    "def save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after):\n",
    "    with open(\"cooking_LDA_pa_task2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [dict_size_before, dict_size_after, corpus_size_before, corpus_size_after]]))\n",
    "\n",
    "save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение когерентностей\n",
    "__Задание 3.__ Постройте еще одну модель по корпусу corpus2 и словарю dictioanary2, остальные параметры оставьте такими же, как при первом построении модели. Сохраните новую модель в другую переменную (не перезаписывайте предыдущую модель). Не забудьте про фиксирование seed!\n",
    "\n",
    "Затем воспользуйтесь методом top_topics модели, чтобы вычислить ее когерентность. Передайте в качестве аргумента соответствующий модели корпус. Метод вернет список кортежей (топ токенов, когерентность), отсортированных по убыванию последней. Вычислите среднюю по всем темам когерентность для каждой из двух моделей и передайте в функцию save_answers3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers3(coherence, coherence2):\n",
    "    with open(\"cooking_LDA_pa_task3.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([\"%3f\"%el for el in [coherence, coherence2]]))\n",
    "        \n",
    "np.random.seed(76543)\n",
    "model2 = models.ldamodel.LdaModel(corpus=corpus2, num_topics=40, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_topics = model.top_topics(corpus)\n",
    "top_topics2 = model2.top_topics(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-624.654818375 -687.656270778\n"
     ]
    }
   ],
   "source": [
    "coherence = sum(coh for _, coh in top_topics) / len(top_topics)\n",
    "coherence2 = sum(coh for _, coh in top_topics2) / len(top_topics2)\n",
    "print(coherence, coherence2)\n",
    "save_answers3(coherence, coherence2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считается, что когерентность хорошо соотносится с человеческими оценками интерпретируемости тем. Поэтому на больших текстовых коллекциях когерентность обычно повышается, если убрать фоновую лексику. Однако в нашем случае этого не произошло. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение влияния гиперпараметра alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы будем работать со второй моделью, то есть той, которая построена по сокращенному корпусу. \n",
    "\n",
    "Пока что мы посмотрели только на матрицу темы-слова, теперь давайте посмотрим на матрицу темы-документы. Выведите темы для нулевого (или любого другого) документа из корпуса, воспользовавшись методом get_document_topics второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выведите содержимое переменной .alpha второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться, что документ характеризуется небольшим числом тем. Попробуем поменять гиперпараметр alpha, задающий априорное распределение Дирихле для распределений тем в документах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__ Обучите третью модель: используйте сокращенный корпус (corpus2 и dictionary2) и установите параметр __alpha=1__, passes=5. Не забудьте задать количество тем и зафиксировать seed! Выведите темы новой модели для нулевого документа; должно получиться, что распределение над множеством тем практически равномерное. Чтобы убедиться в том, что во второй модели документы описываются гораздо более разреженными распределениями, чем в третьей, посчитайте суммарное количество элементов, __превосходящих 0.01__, в матрицах темы-документы обеих моделей. Другими словами, запросите темы  модели для каждого документа с параметром minimum_probability=0.01 и просуммируйте число элементов в получаемых массивах. Передайте две суммы (сначала для модели с alpha по умолчанию, затем для модели в alpha=1) в функцию save_answers4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers4(count_model2, count_model3):\n",
    "    with open(\"cooking_LDA_pa_task4.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [count_model2, count_model3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, гиперпараметр alpha влияет на разреженность распределений тем в документах. Аналогично гиперпараметр eta влияет на разреженность распределений слов в темах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA как способ понижения размерности\n",
    "Иногда распределения над темами, найденные с помощью LDA, добавляют в матрицу объекты-признаки как дополнительные, семантические, признаки, и это может улучшить качество решения задачи. Для простоты давайте просто обучим классификатор рецептов на кухни на признаках, полученных из LDA, и измерим точность (accuracy).\n",
    "\n",
    "__Задание 5.__ Используйте модель, построенную по сокращенной выборке с alpha по умолчанию (вторую модель). Составьте матрицу $\\Theta = p(t|d)$ вероятностей тем в документах; вы можете использовать тот же метод get_document_topics, а также вектор правильных ответов y (в том же порядке, в котором рецепты идут в переменной recipes). Создайте объект RandomForestClassifier со 100 деревьями, с помощью функции cross_val_score вычислите среднюю accuracy по трем фолдам (перемешивать данные не нужно) и передайте в функцию save_answers5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers5(accuracy):\n",
    "     with open(\"cooking_LDA_pa_task5.txt\", \"w\") as fout:\n",
    "        fout.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для такого большого количества классов это неплохая точность. Вы можете попроовать обучать RandomForest на исходной матрице частот слов, имеющей значительно большую размерность, и увидеть, что accuracy увеличивается на 10-15%. Таким образом, LDA собрал не всю, но достаточно большую часть информации из выборки, в матрице низкого ранга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA --- вероятностная модель\n",
    "Матричное разложение, использующееся в LDA, интерпретируется как следующий процесс генерации документов.\n",
    "\n",
    "Для документа $d$ длины $n_d$:\n",
    "1. Из априорного распределения Дирихле с параметром alpha сгенерировать распределение над множеством тем: $\\theta_d \\sim Dirichlet(\\alpha)$\n",
    "1. Для каждого слова $w = 1, \\dots, n_d$:\n",
    "    1. Сгенерировать тему из дискретного распределения $t \\sim \\theta_{d}$\n",
    "    1. Сгенерировать слово из дискретного распределения $w \\sim \\phi_{t}$.\n",
    "    \n",
    "Подробнее об этом в [Википедии](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).\n",
    "\n",
    "В контексте нашей задачи получается, что, используя данный генеративный процесс, можно создавать новые рецепты. Вы можете передать в функцию модель и число ингредиентов и сгенерировать рецепт :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_recipe(model, num_ingredients):\n",
    "    theta = np.random.dirichlet(model.alpha)\n",
    "    for i in range(num_ingredients):\n",
    "        t = np.random.choice(np.arange(model.num_topics), p=theta)\n",
    "        topic = model.show_topic(0, topn=model.num_terms)\n",
    "        topic_distr = [x[1] for x in topic]\n",
    "        terms = [x[0] for x in topic]\n",
    "        w = np.random.choice(terms, p=topic_distr)\n",
    "        print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация построенной модели\n",
    "Вы можете рассмотреть топы ингредиентов каждой темы. Большиснтво тем сами по себе похожи на рецепты; в некоторых собираются продукты одного вида, например, свежие фрукты или разные виды сыра.\n",
    "\n",
    "Попробуем эмпирически соотнести наши темы с национальными кухнями (cuisine). Построим матрицу A размера темы x кухни, ее элементы $a_{tc}$ - суммы p(t|d) по всем документам d, которые отнесены к кухне c. Нормируем матрицу на частоты рецептов по разным кухням, чтобы избежать дисбаланса между кухнями. Следующая функция получает на вход объект модели, объект корпуса и исходные данные и возвращает нормированную матрицу A. Ее удобно визуализировать с помощью seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_topic_cuisine_matrix(model, corpus, recipes):\n",
    "    # составляем вектор целевых признаков\n",
    "    targets = list(set([recipe[\"cuisine\"] for recipe in recipes]))\n",
    "    # составляем матрицу\n",
    "    tc_matrix = pandas.DataFrame(data=np.zeros((model.num_topics, len(targets))), columns=targets)\n",
    "    for recipe, bow in zip(recipes, corpus):\n",
    "        recipe_topic = model.get_document_topics(bow)\n",
    "        for t, prob in recipe_topic:\n",
    "            tc_matrix[recipe[\"cuisine\"]][t] += prob\n",
    "    # нормируем матрицу\n",
    "    target_sums = pandas.DataFrame(data=np.zeros((1, len(targets))), columns=targets)\n",
    "    for recipe in recipes:\n",
    "        target_sums[recipe[\"cuisine\"]] += 1\n",
    "    return pandas.DataFrame(tc_matrix.values/target_sums.values, columns=tc_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix(tc_matrix):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    seaborn.heatmap(tc_matrix, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Визуализируйте матрицу\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем темнее квадрат в матрице, тем больше связь этой темы с данной кухней. Мы видим, что у нас есть темы, которые связаны с несколькими кухнями. Такие темы показывают набор ингредиентов, которые популярны в кухнях нескольких народов, то есть указывают на схожесть кухонь этих народов. Некоторые темы распределены по всем кухням равномерно, они показывают наборы продуктов, которые часто используются в кулинарии всех стран. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жаль, что в датасете нет названий рецептов, иначе темы было бы проще интерпретировать..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение\n",
    "В этом задании вы построили несколько моделей LDA, посмотрели, на что влияют гиперпараметры модели и как можно использовать построенную модель. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
