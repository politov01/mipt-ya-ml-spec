{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment\n",
    "## Готовим LDA по рецептам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже знаете, в тематическом моделировании делается предположение о том, что для определения тематики порядок слов в документе не важен; об этом гласит гипотеза <<мешка слов>>. Сегодня мы будем работать с несколько нестандартной для тематического моделирования коллекцией, которую можно назвать <<мешком ингредиентов>>, потому что на состоит из рецептов блюд разных кухонь. Тематические модели ищут слова, которые часто вместе встречаются в документах, и составляют из них темы. Мы попробуем применить эту идею к рецептам и найти кулинарные <<темы>>. Эта коллекция хороша тем, что не требует предобработки. Кроме того, эта задача достаточно наглядно иллюстрирует принцип работы тематических моделей.\n",
    "\n",
    "Для выполнения заданий, помимо часто используемых в курсе библиотек, потребуются модули json и gensim. Первый входит в дистрибутив Anaconda, второй можно поставить командой \n",
    "\n",
    "pip install gensim\n",
    "\n",
    "или\n",
    "\n",
    "conda install gensim\n",
    "\n",
    "Построение модели занимает некоторое время. На ноутбуке с процессором Intel Core i7 и тактовой частотой 2400 МГц на построение одной модели уходит менее 10 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллекция дана в json-формате: для каждого рецепта известны его id, кухня (\"cuisine\") и список ингредиентов, в него входящих. Загрузить данные можно с помощью модуля json (он входит в дистрибутив Anaconda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"recipes.json\") as f:\n",
    "    recipes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ingredients': ['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles'], 'id': 10259, 'cuisine': 'greek'}\n"
     ]
    }
   ],
   "source": [
    "print(recipes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составление корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша коллекция небольшая и влезает в оперативную память. Gensim может работать с такими данными и не требует их сохранения на диск в специальном формате. Для этого коллекция должна быть представлена в виде списка списков, каждый внутренний список соответствует отдельному документу и состоит из его слов. Пример коллекции из двух документов: \n",
    "\n",
    "[[\"hello\", \"world\"], [\"programming\", \"in\", \"python\"]]\n",
    "\n",
    "Преобразуем наши данные в такой формат, а затем создадим объекты corpus и dictionary, с которыми будет работать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [recipe[\"ingredients\"] for recipe in recipes]\n",
    "dictionary = corpora.Dictionary(texts)   # составляем словарь\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта dictionary есть две полезных переменных: dictionary.id2token и dictionary.token2id; эти словари позволяют находить соответствие между ингредиентами и их индексами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Вам может понадобиться [документация](https://radimrehurek.com/gensim/models/ldamodel.html) LDA в gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучите модель LDA с 40 темами, установив количество проходов по коллекции 5 и оставив остальные параметры по умолчанию. Затем вызовите метод модели show_topics, указав количество тем 40 и количество токенов 10, и сохраните результат (топы ингредиентов в темах) в отдельную переменную. Если при вызове метода show_topics указать параметр formatted=True, то топы ингредиентов будет удобно выводить на печать, если formatted=False, будет удобно работать со списком программно. Выведите топы на печать, рассмотрите темы, а затем ответьте на вопрос:\n",
    "\n",
    "Сколько раз ингредиенты \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\" встретились среди топов-10 всех 40 тем? При ответе __не нужно__ учитывать составные ингредиенты, например, \"hot water\".\n",
    "\n",
    "Передайте 6 чисел в функцию save_answers1 и загрузите сгенерированный файл в форму.\n",
    "\n",
    "У gensim нет возможности фиксировать случайное приближение через параметры метода, но библиотека использует numpy для инициализации матриц. Поэтому, по утверждению автора библиотеки, фиксировать случайное приближение нужно командой, которая написана в следующей ячейке. __Перед строкой кода с построением модели обязательно вставляйте указанную строку фиксации random.seed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers1(c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs):\n",
    "    with open(\"cooking_LDA_pa_task1.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(76543)\n",
    "model = models.ldamodel.LdaModel(corpus=corpus, num_topics=40, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('45', 0.076982971656143387),\n",
       "   ('305', 0.076006488298713815),\n",
       "   ('11', 0.053001971841181973),\n",
       "   ('55', 0.051177733676344442),\n",
       "   ('22', 0.043096888130629889),\n",
       "   ('84', 0.0397969302135531),\n",
       "   ('128', 0.034968982031880778),\n",
       "   ('554', 0.029240238805320028),\n",
       "   ('12', 0.028805109095701057),\n",
       "   ('36', 0.028039209143666276)]),\n",
       " (1,\n",
       "  [('120', 0.055920005797528288),\n",
       "   ('181', 0.055543284409957094),\n",
       "   ('486', 0.054301629125219096),\n",
       "   ('1174', 0.04184350765470881),\n",
       "   ('1050', 0.041212706987356615),\n",
       "   ('1211', 0.040744861921155236),\n",
       "   ('1085', 0.036649252631752151),\n",
       "   ('29', 0.034924306112800535),\n",
       "   ('756', 0.03243804759156927),\n",
       "   ('585', 0.029866680542748842)]),\n",
       " (2,\n",
       "  [('55', 0.071390557322931023),\n",
       "   ('11', 0.051098264513947528),\n",
       "   ('77', 0.045410810624427082),\n",
       "   ('103', 0.040933838054010491),\n",
       "   ('490', 0.038914140829257329),\n",
       "   ('3', 0.033802552794070462),\n",
       "   ('12', 0.031451282325837181),\n",
       "   ('19', 0.031030695304113808),\n",
       "   ('391', 0.028769675982427502),\n",
       "   ('553', 0.026100555091856749)]),\n",
       " (3,\n",
       "  [('314', 0.22326324928948546),\n",
       "   ('555', 0.067222211032255577),\n",
       "   ('319', 0.056678517100441521),\n",
       "   ('686', 0.044346471530897345),\n",
       "   ('76', 0.037193695365119107),\n",
       "   ('1036', 0.030018304940044215),\n",
       "   ('434', 0.028136177806839659),\n",
       "   ('590', 0.028048615326658692),\n",
       "   ('1339', 0.023917273329442646),\n",
       "   ('397', 0.023840579913511663)]),\n",
       " (4,\n",
       "  [('209', 0.098870994012440774),\n",
       "   ('213', 0.070445923683949488),\n",
       "   ('11', 0.0479452979220217),\n",
       "   ('22', 0.036138635130597785),\n",
       "   ('874', 0.03563776292500842),\n",
       "   ('737', 0.034926491909790768),\n",
       "   ('625', 0.033611858542043661),\n",
       "   ('439', 0.027147404083033778),\n",
       "   ('15', 0.025932507951071979),\n",
       "   ('95', 0.025899691825369789)]),\n",
       " (5,\n",
       "  [('11', 0.088583023714964348),\n",
       "   ('61', 0.070117809318677712),\n",
       "   ('3', 0.067854784607595336),\n",
       "   ('68', 0.062688055659829017),\n",
       "   ('113', 0.055900991870113909),\n",
       "   ('110', 0.046148992968442284),\n",
       "   ('1', 0.045172950542614117),\n",
       "   ('19', 0.044438848451437724),\n",
       "   ('58', 0.040345235487766917),\n",
       "   ('840', 0.038987105584716103)]),\n",
       " (6,\n",
       "  [('28', 0.10566869697101158),\n",
       "   ('187', 0.10176177897152065),\n",
       "   ('40', 0.053290663291528026),\n",
       "   ('949', 0.046082939073278061),\n",
       "   ('525', 0.042283193779732248),\n",
       "   ('62', 0.037327433392223705),\n",
       "   ('42', 0.03501688443312749),\n",
       "   ('12', 0.030710943499903547),\n",
       "   ('79', 0.027786680741259933),\n",
       "   ('419', 0.025659124800512287)]),\n",
       " (7,\n",
       "  [('271', 0.10546269748700265),\n",
       "   ('577', 0.064321945687514884),\n",
       "   ('204', 0.063498306141481067),\n",
       "   ('245', 0.056114560263402488),\n",
       "   ('75', 0.038873981099487101),\n",
       "   ('43', 0.038207368797863524),\n",
       "   ('519', 0.036295381851000945),\n",
       "   ('144', 0.02572501446844366),\n",
       "   ('73', 0.024463802911079243),\n",
       "   ('697', 0.023671928528529871)]),\n",
       " (8,\n",
       "  [('18', 0.10675549719530593),\n",
       "   ('10', 0.10121596079331295),\n",
       "   ('11', 0.08428523489323575),\n",
       "   ('22', 0.081668795809388461),\n",
       "   ('63', 0.079856234249116378),\n",
       "   ('53', 0.056447499228387078),\n",
       "   ('29', 0.028185752088693637),\n",
       "   ('597', 0.024589614709152222),\n",
       "   ('1073', 0.02237212127295983),\n",
       "   ('4', 0.019094768431285714)]),\n",
       " (9,\n",
       "  [('1336', 0.04282106805353568),\n",
       "   ('313', 0.04090044940781036),\n",
       "   ('533', 0.039902560620211941),\n",
       "   ('1743', 0.039760451677312979),\n",
       "   ('879', 0.039664019179356136),\n",
       "   ('55', 0.038999423137796682),\n",
       "   ('119', 0.037219821446912556),\n",
       "   ('36', 0.032181397505044451),\n",
       "   ('11', 0.031706145207522025),\n",
       "   ('400', 0.031254991619129549)]),\n",
       " (10,\n",
       "  [('707', 0.052555237299654396),\n",
       "   ('938', 0.046504227808947418),\n",
       "   ('176', 0.040878601378825527),\n",
       "   ('1528', 0.036679762649266458),\n",
       "   ('300', 0.031834557057071049),\n",
       "   ('598', 0.02956196766588336),\n",
       "   ('668', 0.029420046747040095),\n",
       "   ('682', 0.029266921377301865),\n",
       "   ('960', 0.027092537094678314),\n",
       "   ('630', 0.026338116576475133)]),\n",
       " (11,\n",
       "  [('464', 0.059828860659191699),\n",
       "   ('79', 0.054382242082853187),\n",
       "   ('1', 0.050004230601201342),\n",
       "   ('60', 0.041290090394866162),\n",
       "   ('467', 0.038747976774498046),\n",
       "   ('55', 0.038283513979577403),\n",
       "   ('23', 0.037055089634967397),\n",
       "   ('873', 0.029767118586281366),\n",
       "   ('350', 0.027655624662172848),\n",
       "   ('103', 0.025797782636961718)]),\n",
       " (12,\n",
       "  [('730', 0.13657444175777583),\n",
       "   ('274', 0.060695893443767704),\n",
       "   ('798', 0.058884882798762944),\n",
       "   ('142', 0.05721947230873084),\n",
       "   ('190', 0.049746647546630302),\n",
       "   ('227', 0.042082259133490854),\n",
       "   ('302', 0.03745911579010261),\n",
       "   ('36', 0.029344795316199667),\n",
       "   ('1044', 0.029299424695894614),\n",
       "   ('87', 0.028577527068561637)]),\n",
       " (13,\n",
       "  [('404', 0.090598521984040614),\n",
       "   ('448', 0.076940387475529393),\n",
       "   ('99', 0.066373432162825249),\n",
       "   ('789', 0.058612663616318728),\n",
       "   ('827', 0.0495218290030544),\n",
       "   ('309', 0.043507591647283905),\n",
       "   ('124', 0.040346897660399117),\n",
       "   ('308', 0.035403433480332328),\n",
       "   ('749', 0.030693218376913439),\n",
       "   ('276', 0.02921430267527652)]),\n",
       " (14,\n",
       "  [('78', 0.06559700873792973),\n",
       "   ('307', 0.061119909487201342),\n",
       "   ('55', 0.059889910171449859),\n",
       "   ('188', 0.050709347469700176),\n",
       "   ('11', 0.046861689055581794),\n",
       "   ('230', 0.044764734542748284),\n",
       "   ('103', 0.044496884027386607),\n",
       "   ('83', 0.032800665398067232),\n",
       "   ('118', 0.029767601079591602),\n",
       "   ('500', 0.021459058746919626)]),\n",
       " (15,\n",
       "  [('191', 0.16065533619915312),\n",
       "   ('311', 0.14564462203102163),\n",
       "   ('441', 0.069344569589893046),\n",
       "   ('459', 0.05623907970405756),\n",
       "   ('50', 0.041562604892565573),\n",
       "   ('79', 0.035088551343642228),\n",
       "   ('803', 0.031007999318265429),\n",
       "   ('132', 0.028717085479460218),\n",
       "   ('702', 0.027725172614061253),\n",
       "   ('460', 0.027129812013070388)]),\n",
       " (16,\n",
       "  [('228', 0.080242076816783262),\n",
       "   ('146', 0.069676703812525789),\n",
       "   ('36', 0.061177986799951907),\n",
       "   ('200', 0.051937879073970204),\n",
       "   ('37', 0.04725658823531298),\n",
       "   ('55', 0.040377558241251943),\n",
       "   ('43', 0.03525414364191936),\n",
       "   ('11', 0.034669367239461402),\n",
       "   ('1', 0.028615711863733496),\n",
       "   ('227', 0.023293957935036282)]),\n",
       " (17,\n",
       "  [('432', 0.0929023660827175),\n",
       "   ('669', 0.076414698662258765),\n",
       "   ('646', 0.073396812456205052),\n",
       "   ('433', 0.07243562666816962),\n",
       "   ('621', 0.051985157913376316),\n",
       "   ('251', 0.047468264648236232),\n",
       "   ('431', 0.039219371377701581),\n",
       "   ('241', 0.03856133374007454),\n",
       "   ('29', 0.029347387288341908),\n",
       "   ('1286', 0.023517887648534748)]),\n",
       " (18,\n",
       "  [('148', 0.083439137695740462),\n",
       "   ('164', 0.071347710392759334),\n",
       "   ('203', 0.066966635726777413),\n",
       "   ('270', 0.057259409733351668),\n",
       "   ('157', 0.040253376322449533),\n",
       "   ('1343', 0.032686879987386251),\n",
       "   ('1395', 0.02916520530865593),\n",
       "   ('1089', 0.028809943166330922),\n",
       "   ('940', 0.02638393617456784),\n",
       "   ('521', 0.026147176041695853)]),\n",
       " (19,\n",
       "  [('321', 0.10304182537513287),\n",
       "   ('1223', 0.048182475100058228),\n",
       "   ('703', 0.047859758955429862),\n",
       "   ('1348', 0.045033791404173629),\n",
       "   ('273', 0.042536628779240346),\n",
       "   ('339', 0.040284197923680869),\n",
       "   ('360', 0.032081767342536219),\n",
       "   ('359', 0.031956928713725928),\n",
       "   ('1570', 0.029274559954221402),\n",
       "   ('480', 0.025397674606502732)]),\n",
       " (20,\n",
       "  [('36', 0.071742096970665928),\n",
       "   ('215', 0.069217904925082632),\n",
       "   ('327', 0.069020112029264363),\n",
       "   ('175', 0.051622647568351714),\n",
       "   ('928', 0.046673828864191233),\n",
       "   ('565', 0.043611572035047216),\n",
       "   ('9', 0.043360206224285464),\n",
       "   ('11', 0.043277769767526932),\n",
       "   ('911', 0.036898764891540779),\n",
       "   ('4', 0.033808858403417082)]),\n",
       " (21,\n",
       "  [('237', 0.078166987736098634),\n",
       "   ('208', 0.051592285033923463),\n",
       "   ('212', 0.04897062582714376),\n",
       "   ('227', 0.040876647538322396),\n",
       "   ('916', 0.036769904201479645),\n",
       "   ('234', 0.031983396405361332),\n",
       "   ('211', 0.029910310432673337),\n",
       "   ('12', 0.029722878702230827),\n",
       "   ('235', 0.029685571437990339),\n",
       "   ('192', 0.02925671593264087)]),\n",
       " (22,\n",
       "  [('252', 0.11455915133864907),\n",
       "   ('596', 0.060169017207233222),\n",
       "   ('1242', 0.048314033105298387),\n",
       "   ('416', 0.04799143736381651),\n",
       "   ('74', 0.040185771056679018),\n",
       "   ('569', 0.038790097389873962),\n",
       "   ('522', 0.032536311730376244),\n",
       "   ('1031', 0.031981446063523628),\n",
       "   ('334', 0.023982752066051431),\n",
       "   ('1777', 0.022428782667886806)]),\n",
       " (23,\n",
       "  [('20', 0.101088119161485),\n",
       "   ('91', 0.051754603766480181),\n",
       "   ('53', 0.043978052526878468),\n",
       "   ('1', 0.041701897866763767),\n",
       "   ('96', 0.039976181559999123),\n",
       "   ('227', 0.034844174444637492),\n",
       "   ('29', 0.032262201706037677),\n",
       "   ('90', 0.032236914852918172),\n",
       "   ('361', 0.031740813648502564),\n",
       "   ('11', 0.029524377647968812)]),\n",
       " (24,\n",
       "  [('141', 0.089176599775448853),\n",
       "   ('70', 0.069396982372971719),\n",
       "   ('103', 0.046084663602443073),\n",
       "   ('562', 0.034306829029946549),\n",
       "   ('11', 0.03358084230445478),\n",
       "   ('79', 0.025483046047562279),\n",
       "   ('53', 0.025028760526387472),\n",
       "   ('860', 0.024632018928548632),\n",
       "   ('37', 0.02411309698540974),\n",
       "   ('820', 0.023417706201799324)]),\n",
       " (25,\n",
       "  [('11', 0.076669709408418871),\n",
       "   ('36', 0.056014092834438339),\n",
       "   ('346', 0.041055402881171266),\n",
       "   ('44', 0.038630689005429208),\n",
       "   ('46', 0.03789577477546141),\n",
       "   ('275', 0.034996503255996667),\n",
       "   ('37', 0.033173048968449928),\n",
       "   ('126', 0.031731732808651096),\n",
       "   ('1', 0.030850552030296491),\n",
       "   ('349', 0.030259034833267941)]),\n",
       " (26,\n",
       "  [('102', 0.17409676092474691),\n",
       "   ('77', 0.049264968369976819),\n",
       "   ('375', 0.04013149630201588),\n",
       "   ('103', 0.039968891472133769),\n",
       "   ('11', 0.036998990016276052),\n",
       "   ('172', 0.036081206305374793),\n",
       "   ('55', 0.035900505837790725),\n",
       "   ('551', 0.034016954206362873),\n",
       "   ('510', 0.032498942868147501),\n",
       "   ('12', 0.030213768338061379)]),\n",
       " (27,\n",
       "  [('77', 0.11739850745413176),\n",
       "   ('255', 0.075258314169435153),\n",
       "   ('11', 0.056900321302291376),\n",
       "   ('396', 0.048309413520425809),\n",
       "   ('57', 0.040247632003897096),\n",
       "   ('699', 0.032809692286778838),\n",
       "   ('103', 0.032777376941787686),\n",
       "   ('861', 0.031980996858813074),\n",
       "   ('79', 0.030415367628003651),\n",
       "   ('55', 0.029834037858320568)]),\n",
       " (28,\n",
       "  [('36', 0.088613271719701001),\n",
       "   ('11', 0.068690712803748555),\n",
       "   ('198', 0.062952728351756332),\n",
       "   ('1', 0.04517494115776631),\n",
       "   ('29', 0.039199463800154981),\n",
       "   ('210', 0.039030860209479622),\n",
       "   ('34', 0.034449251083190732),\n",
       "   ('4', 0.034229280648126734),\n",
       "   ('55', 0.032100950439312249),\n",
       "   ('248', 0.031424142179892103)]),\n",
       " (29,\n",
       "  [('1077', 0.078298214497411214),\n",
       "   ('746', 0.048629986707287208),\n",
       "   ('53', 0.042681140466245909),\n",
       "   ('711', 0.028665162602805605),\n",
       "   ('888', 0.026956931393927838),\n",
       "   ('828', 0.026759560801062111),\n",
       "   ('317', 0.026487750513915016),\n",
       "   ('853', 0.024325708908846101),\n",
       "   ('1366', 0.022738687910267348),\n",
       "   ('2029', 0.022368501425440279)]),\n",
       " (30,\n",
       "  [('53', 0.12638822218502646),\n",
       "   ('304', 0.069021392302470105),\n",
       "   ('48', 0.053170377978363999),\n",
       "   ('532', 0.051550292570576368),\n",
       "   ('364', 0.047000580013045197),\n",
       "   ('29', 0.044275456315179554),\n",
       "   ('205', 0.037110376300090737),\n",
       "   ('201', 0.034643831107070769),\n",
       "   ('407', 0.031656783371423379),\n",
       "   ('11', 0.029683851122788357)]),\n",
       " (31,\n",
       "  [('280', 0.11258463771865669),\n",
       "   ('11', 0.055457853411840952),\n",
       "   ('207', 0.054689003341726293),\n",
       "   ('103', 0.051890318857915264),\n",
       "   ('306', 0.045261439947574443),\n",
       "   ('504', 0.039711421958691831),\n",
       "   ('115', 0.039589526455754684),\n",
       "   ('29', 0.0374715596170411),\n",
       "   ('773', 0.037074890212978197),\n",
       "   ('118', 0.036083878605264096)]),\n",
       " (32,\n",
       "  [('225', 0.08934461324017659),\n",
       "   ('357', 0.05288041515396523),\n",
       "   ('1', 0.037650140287642013),\n",
       "   ('68', 0.031955631574158136),\n",
       "   ('338', 0.03016346495479966),\n",
       "   ('53', 0.030031704438525507),\n",
       "   ('29', 0.026557999686869515),\n",
       "   ('198', 0.026002985657255454),\n",
       "   ('995', 0.025020499564607536),\n",
       "   ('129', 0.024452720986764438)]),\n",
       " (33,\n",
       "  [('578', 0.11126544660788255),\n",
       "   ('641', 0.072172846123474604),\n",
       "   ('721', 0.060702139327245289),\n",
       "   ('481', 0.059787879497508502),\n",
       "   ('505', 0.053609908442986319),\n",
       "   ('170', 0.053280238887833405),\n",
       "   ('86', 0.040248704604890453),\n",
       "   ('1311', 0.034757709771121192),\n",
       "   ('195', 0.030645915202653203),\n",
       "   ('402', 0.023858522072323748)]),\n",
       " (34,\n",
       "  [('25', 0.075556613503413972),\n",
       "   ('11', 0.057184399085087045),\n",
       "   ('188', 0.043306532879780334),\n",
       "   ('1', 0.043304181019252395),\n",
       "   ('216', 0.03867472846254108),\n",
       "   ('713', 0.035197848142459777),\n",
       "   ('4', 0.035160297438590588),\n",
       "   ('394', 0.034017649643354374),\n",
       "   ('262', 0.032602003212027081),\n",
       "   ('55', 0.032408594164050564)]),\n",
       " (35,\n",
       "  [('52', 0.11544682789526627),\n",
       "   ('51', 0.062992726148172057),\n",
       "   ('369', 0.054208131992209488),\n",
       "   ('389', 0.046966260578958384),\n",
       "   ('446', 0.039355665693539606),\n",
       "   ('495', 0.037754013848586163),\n",
       "   ('542', 0.037266105328494878),\n",
       "   ('830', 0.027784365214768288),\n",
       "   ('388', 0.026914442727205858),\n",
       "   ('513', 0.025661254751573711)]),\n",
       " (36,\n",
       "  [('54', 0.095391416975710061),\n",
       "   ('149', 0.076245450555699326),\n",
       "   ('220', 0.070363546799684651),\n",
       "   ('206', 0.053849480356866535),\n",
       "   ('155', 0.052844143740732583),\n",
       "   ('501', 0.039017328587065671),\n",
       "   ('14', 0.03674419843914449),\n",
       "   ('482', 0.031090245890500683),\n",
       "   ('151', 0.025683881399095582),\n",
       "   ('1572', 0.025324518867076529)]),\n",
       " (37,\n",
       "  [('121', 0.16302859875901154),\n",
       "   ('11', 0.10131042828495664),\n",
       "   ('201', 0.088134080374078827),\n",
       "   ('47', 0.059104729710040493),\n",
       "   ('22', 0.047902186310940217),\n",
       "   ('53', 0.046927976962497023),\n",
       "   ('311', 0.045378392620879685),\n",
       "   ('310', 0.038000285655980078),\n",
       "   ('290', 0.033286785666502415),\n",
       "   ('10', 0.029808352007935718)]),\n",
       " (38,\n",
       "  [('229', 0.097264850545365267),\n",
       "   ('477', 0.083179535815715314),\n",
       "   ('29', 0.072085128165738421),\n",
       "   ('11', 0.069049791318578788),\n",
       "   ('320', 0.052610885019654163),\n",
       "   ('199', 0.051076220376126101),\n",
       "   ('24', 0.040197954445412208),\n",
       "   ('1', 0.032843311183230119),\n",
       "   ('18', 0.032033487676905982),\n",
       "   ('36', 0.030800901629714952)]),\n",
       " (39,\n",
       "  [('214', 0.087760673976439801),\n",
       "   ('55', 0.0772546407504828),\n",
       "   ('679', 0.04732623705630374),\n",
       "   ('11', 0.0453605839734567),\n",
       "   ('22', 0.044729552561556252),\n",
       "   ('12', 0.035560891340588326),\n",
       "   ('121', 0.031748981954884126),\n",
       "   ('36', 0.030722832091069671),\n",
       "   ('476', 0.028903841977693599),\n",
       "   ('188', 0.027448364197368937)])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topics(num_topics=40, num_words=10, formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 7, 9, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "params1 = [\n",
    "    sum(\n",
    "        str(dictionary.token2id[token]) == _id\n",
    "        for topic, top in model.show_topics(num_topics=40, num_words=10, formatted=False)\n",
    "        for _id, _ in top\n",
    "    )\n",
    "    for token in [\"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\"]\n",
    "]\n",
    "print(params1)\n",
    "save_answers1(*params1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация словаря\n",
    "В топах тем гораздо чаще встречаются первые три рассмотренных ингредиента, чем последние три. При этом наличие в рецепте курицы, яиц и грибов яснее дает понять, что мы будем готовить, чем наличие соли, сахара и воды. Таким образом, даже в рецептах есть слова, часто встречающиеся в текстах и не несущие смысловой нагрузки, и поэтому их не желательно видеть в темах. Наиболее простой прием борьбы с такими фоновыми элементами - фильтрация словаря по частоте. Обычно словарь фильтруют с двух сторон: убирают очень редкие слова (в целях экономии памяти) и очень частые слова (в целях повышения интерпретируемости тем). Мы уберем только частые слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ У объекта dictionary2 есть переменная dfs - это словарь, ключами которого являются id токена, а элементами - число раз, сколько слово встретилось во всей коллекции. Сохраните в отдельный список ингредиенты, которые встретились в коллекции больше 4000 раз. Вызовите метод словаря filter_tokens, подав в качестве первого аргумента полученный список популярных ингредиентов. Вычислите две величины: dict_size_before и dict_size_after - размер словаря до и после фильтрации.\n",
    "\n",
    "Затем, используя новый словарь, создайте новый корпус документов, corpus2, по аналогии с тем, как это сделано в начале ноутбука. Вычислите две величины: corpus_size_before и corpus_size_after - суммарное количество ингредиентов в корпусе (иными словами, сумма длин всех документов коллекции) до и после фильтрации.\n",
    "\n",
    "Передайте величины dict_size_before, dict_size_after, corpus_size_before, corpus_size_after в функцию save_answers2 и загрузите сгенерированный файл в форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top: [(11, 18048), (36, 7972), (55, 7971), (29, 7457), (1, 7380), (53, 6434), (103, 6236), (22, 4847), (12, 4784), (121, 4632), (4, 4438), (14, 4385), (18, 3388), (20, 3296), (79, 3113), (227, 3078), (19, 3058), (201, 2948), (198, 2814), (311, 2782)]\n",
      "IDs: [1, 4, 11, 12, 14, 22, 29, 36, 53, 55, 103, 121]\n",
      "Dict size before: 6714\n",
      "Dict size after: 6702\n",
      "Corpus size before: 428249\n",
      "Corpus size after: 343665\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "dictionary2 = copy.deepcopy(dictionary)\n",
    "\n",
    "print(\"Top:\", sorted(dictionary2.dfs.items(), key=lambda item: item[1], reverse=True)[:20])\n",
    "ids2 = [_id for _id, freq in dictionary2.dfs.items() if freq > 4000]\n",
    "print(\"IDs:\", ids2)\n",
    "\n",
    "dict_size_before = len(dictionary)\n",
    "print(\"Dict size before:\", dict_size_before)\n",
    "dictionary2.filter_tokens(ids2)\n",
    "dict_size_after = len(dictionary2)\n",
    "print(\"Dict size after:\", dict_size_after)\n",
    "\n",
    "corpus_size_before = sum(1 for doc in corpus for _, count in doc)\n",
    "print(\"Corpus size before:\", corpus_size_before)\n",
    "corpus2 = [dictionary2.doc2bow(text) for text in texts]\n",
    "corpus_size_after = sum(1 for doc in corpus2 for _, count in doc)\n",
    "print(\"Corpus size after:\", corpus_size_after)\n",
    "\n",
    "def save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after):\n",
    "    with open(\"cooking_LDA_pa_task2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [dict_size_before, dict_size_after, corpus_size_before, corpus_size_after]]))\n",
    "\n",
    "save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение когерентностей\n",
    "__Задание 3.__ Постройте еще одну модель по корпусу corpus2 и словарю dictioanary2, остальные параметры оставьте такими же, как при первом построении модели. Сохраните новую модель в другую переменную (не перезаписывайте предыдущую модель). Не забудьте про фиксирование seed!\n",
    "\n",
    "Затем воспользуйтесь методом top_topics модели, чтобы вычислить ее когерентность. Передайте в качестве аргумента соответствующий модели корпус. Метод вернет список кортежей (топ токенов, когерентность), отсортированных по убыванию последней. Вычислите среднюю по всем темам когерентность для каждой из двух моделей и передайте в функцию save_answers3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers3(coherence, coherence2):\n",
    "    with open(\"cooking_LDA_pa_task3.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([\"%3f\"%el for el in [coherence, coherence2]]))\n",
    "        \n",
    "np.random.seed(76543)\n",
    "model2 = models.ldamodel.LdaModel(corpus=corpus2, num_topics=40, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_topics = model.top_topics(corpus)\n",
    "top_topics2 = model2.top_topics(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-624.654818375 -687.656270778\n"
     ]
    }
   ],
   "source": [
    "coherence = sum(coh for _, coh in top_topics) / len(top_topics)\n",
    "coherence2 = sum(coh for _, coh in top_topics2) / len(top_topics2)\n",
    "print(coherence, coherence2)\n",
    "save_answers3(coherence, coherence2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считается, что когерентность хорошо соотносится с человеческими оценками интерпретируемости тем. Поэтому на больших текстовых коллекциях когерентность обычно повышается, если убрать фоновую лексику. Однако в нашем случае этого не произошло. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение влияния гиперпараметра alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы будем работать со второй моделью, то есть той, которая построена по сокращенному корпусу. \n",
    "\n",
    "Пока что мы посмотрели только на матрицу темы-слова, теперь давайте посмотрим на матрицу темы-документы. Выведите темы для нулевого (или любого другого) документа из корпуса, воспользовавшись методом get_document_topics второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 0.12812499999999999),\n",
       " (31, 0.48460927673683979),\n",
       " (33, 0.14664072326315999),\n",
       " (37, 0.12812499999999996)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.get_document_topics(corpus2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выведите содержимое переменной .alpha второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться, что документ характеризуется небольшим числом тем. Попробуем поменять гиперпараметр alpha, задающий априорное распределение Дирихле для распределений тем в документах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__ Обучите третью модель: используйте сокращенный корпус (corpus2 и dictionary2) и установите параметр __alpha=1__, passes=5. Не забудьте задать количество тем и зафиксировать seed! Выведите темы новой модели для нулевого документа; должно получиться, что распределение над множеством тем практически равномерное. Чтобы убедиться в том, что во второй модели документы описываются гораздо более разреженными распределениями, чем в третьей, посчитайте суммарное количество элементов, __превосходящих 0.01__, в матрицах темы-документы обеих моделей. Другими словами, запросите темы  модели для каждого документа с параметром minimum_probability=0.01 и просуммируйте число элементов в получаемых массивах. Передайте две суммы (сначала для модели с alpha по умолчанию, затем для модели в alpha=1) в функцию save_answers4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers4(count_model2, count_model3):\n",
    "    with open(\"cooking_LDA_pa_task4.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [count_model2, count_model3]]))\n",
    "        \n",
    "np.random.seed(76543)\n",
    "model3 = models.ldamodel.LdaModel(corpus=corpus2, num_topics=40, passes=5, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_model2 = sum(len(model2.get_document_topics(doc, minimum_probability=0.01)) for doc in corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_model3 = sum(len(model3.get_document_topics(doc, minimum_probability=0.01)) for doc in corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_answers4(count_model2, count_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, гиперпараметр alpha влияет на разреженность распределений тем в документах. Аналогично гиперпараметр eta влияет на разреженность распределений слов в темах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA как способ понижения размерности\n",
    "Иногда распределения над темами, найденные с помощью LDA, добавляют в матрицу объекты-признаки как дополнительные, семантические, признаки, и это может улучшить качество решения задачи. Для простоты давайте просто обучим классификатор рецептов на кухни на признаках, полученных из LDA, и измерим точность (accuracy).\n",
    "\n",
    "__Задание 5.__ Используйте модель, построенную по сокращенной выборке с alpha по умолчанию (вторую модель). Составьте матрицу $\\Theta = p(t|d)$ вероятностей тем в документах; вы можете использовать тот же метод get_document_topics, а также вектор правильных ответов y (в том же порядке, в котором рецепты идут в переменной recipes). Создайте объект RandomForestClassifier со 100 деревьями, с помощью функции cross_val_score вычислите среднюю accuracy по трем фолдам (перемешивать данные не нужно) и передайте в функцию save_answers5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.array([recipe[\"cuisine\"] for recipe in recipes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def topics_to_array(topics):\n",
    "    array = np.zeros((40, ))\n",
    "    for index, value in topics:\n",
    "        array[index - 1] = value\n",
    "    return array\n",
    "\n",
    "X = np.array([topics_to_array(model2.get_document_topics(doc)) for doc in corpus2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 40)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.544377203626\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(RandomForestClassifier(n_estimators=100), X, y, scoring=\"accuracy\").mean()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers5(accuracy):\n",
    "     with open(\"cooking_LDA_pa_task5.txt\", \"w\") as fout:\n",
    "        fout.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_answers5(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для такого большого количества классов это неплохая точность. Вы можете попроовать обучать RandomForest на исходной матрице частот слов, имеющей значительно большую размерность, и увидеть, что accuracy увеличивается на 10-15%. Таким образом, LDA собрал не всю, но достаточно большую часть информации из выборки, в матрице низкого ранга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA --- вероятностная модель\n",
    "Матричное разложение, использующееся в LDA, интерпретируется как следующий процесс генерации документов.\n",
    "\n",
    "Для документа $d$ длины $n_d$:\n",
    "1. Из априорного распределения Дирихле с параметром alpha сгенерировать распределение над множеством тем: $\\theta_d \\sim Dirichlet(\\alpha)$\n",
    "1. Для каждого слова $w = 1, \\dots, n_d$:\n",
    "    1. Сгенерировать тему из дискретного распределения $t \\sim \\theta_{d}$\n",
    "    1. Сгенерировать слово из дискретного распределения $w \\sim \\phi_{t}$.\n",
    "    \n",
    "Подробнее об этом в [Википедии](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).\n",
    "\n",
    "В контексте нашей задачи получается, что, используя данный генеративный процесс, можно создавать новые рецепты. Вы можете передать в функцию модель и число ингредиентов и сгенерировать рецепт :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_recipe(model, num_ingredients):\n",
    "    theta = np.random.dirichlet(model.alpha)\n",
    "    for i in range(num_ingredients):\n",
    "        t = np.random.choice(np.arange(model.num_topics), p=theta)\n",
    "        topic = model.show_topic(0, topn=model.num_terms)\n",
    "        topic_distr = [x[1] for x in topic]\n",
    "        terms = [x[0] for x in topic]\n",
    "        w = np.random.choice(terms, p=topic_distr)\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n",
      "4687\n",
      "3655\n",
      "5105\n",
      "6093\n"
     ]
    }
   ],
   "source": [
    "generate_recipe(model2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация построенной модели\n",
    "Вы можете рассмотреть топы ингредиентов каждой темы. Большиснтво тем сами по себе похожи на рецепты; в некоторых собираются продукты одного вида, например, свежие фрукты или разные виды сыра.\n",
    "\n",
    "Попробуем эмпирически соотнести наши темы с национальными кухнями (cuisine). Построим матрицу A размера темы x кухни, ее элементы $a_{tc}$ - суммы p(t|d) по всем документам d, которые отнесены к кухне c. Нормируем матрицу на частоты рецептов по разным кухням, чтобы избежать дисбаланса между кухнями. Следующая функция получает на вход объект модели, объект корпуса и исходные данные и возвращает нормированную матрицу A. Ее удобно визуализировать с помощью seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_topic_cuisine_matrix(model, corpus, recipes):\n",
    "    # составляем вектор целевых признаков\n",
    "    targets = list(set([recipe[\"cuisine\"] for recipe in recipes]))\n",
    "    # составляем матрицу\n",
    "    tc_matrix = pandas.DataFrame(data=np.zeros((model.num_topics, len(targets))), columns=targets)\n",
    "    for recipe, bow in zip(recipes, corpus):\n",
    "        recipe_topic = model.get_document_topics(bow)\n",
    "        for t, prob in recipe_topic:\n",
    "            tc_matrix[recipe[\"cuisine\"]][t] += prob\n",
    "    # нормируем матрицу\n",
    "    target_sums = pandas.DataFrame(data=np.zeros((1, len(targets))), columns=targets)\n",
    "    for recipe in recipes:\n",
    "        target_sums[recipe[\"cuisine\"]] += 1\n",
    "    return pandas.DataFrame(tc_matrix.values/target_sums.values, columns=tc_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix(tc_matrix):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    seaborn.heatmap(tc_matrix, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAJ8CAYAAAAVo205AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4BAEQRDM4f+W0RcykVERtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c2c3160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Визуализируйте матрицу\n",
    "plot_matrix(compute_topic_cuisine_matrix(model2, corpus2, recipes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем темнее квадрат в матрице, тем больше связь этой темы с данной кухней. Мы видим, что у нас есть темы, которые связаны с несколькими кухнями. Такие темы показывают набор ингредиентов, которые популярны в кухнях нескольких народов, то есть указывают на схожесть кухонь этих народов. Некоторые темы распределены по всем кухням равномерно, они показывают наборы продуктов, которые часто используются в кулинарии всех стран. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жаль, что в датасете нет названий рецептов, иначе темы было бы проще интерпретировать..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение\n",
    "В этом задании вы построили несколько моделей LDA, посмотрели, на что влияют гиперпараметры модели и как можно использовать построенную модель. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
